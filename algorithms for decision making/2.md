*Extracted from [Algorithms for Decision-Making][1]*
**

### 2.2.2 Continuous Probability Distributions
Gaussian mixture model is a mixture model that is simply a weighted average of various Gaussian distributions. The parameters of a Gaussian mixture model include the parameters of the Gaussian distribution components $\mu_{1:n},\sigma^{2}_{1:n}$, as well as their weights $\rho_{1:n}$. The density is given by:

$$p(x|\mu_{1:n},\sigma^{2}_{1:n},\rho_{1:n}) = \sum_{i=1..n}{\rho_i \mathscr{N}(x|\mu_i,\sigma_i)}$$

the weights $\rho_{1:n}$ are nothing more than a convex combination, therefore is just a weighted sum of normals, it looks like this:

<img src="img/gaussian_mixture_model.png" alt="alt text" width="500"/>

## 2.3 Joint Distributions
A joint distribution is a probability distribution over multiple variables. A distribution over a single variable is called a *univariate distribution*, and a distribution over multiple variables is called a *multivariate distribution*. If we have a joint distribution over two discrete variables $X$ and $Y$, then $P(x, y)$ denotes the probability that both $X = x$ and $Y = y$.

We can represent joint distributions in terms of factors. A factor $\phi$ over a set of variables is a function from assignments of those variables to the real numbers. In order to represent a probability distribution, the real numbers in the factor must be nonnegative. A factor with nonnegative values can be **normalized** such that it represents a probability distribution.



[Comment]: References 
[1]: <https://algorithmsbook.com/>
[2]: <https://juliaacademy.com/>